{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def set_seed(seed: int):\n",
        "    \"\"\"\n",
        "    Set seeds for reproducibility.\n",
        "\n",
        "    Parameters:\n",
        "    seed (int): Seed value.\n",
        "    \"\"\"\n",
        "    # Pythonの組み込み乱数生成器のシードを固定\n",
        "    random.seed(seed)\n",
        "\n",
        "    # NumPyの乱数シードを固定\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # PyTorchの乱数シードを固定\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    # GPUが利用可能な場合の追加設定\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)  # 複数GPU用\n",
        "\n",
        "    # PyTorchの再現性を確保する追加設定\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# 再現性のためのシードを固定\n",
        "set_seed(42)"
      ],
      "metadata": {
        "id": "kjVLt4xNZZmH"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LICA3ibBLLv6",
        "outputId": "e6e7d911-4b07-4db4-966b-604dbb0edeb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Time Series Shape: torch.Size([32, 100])\n",
            "Sample NLP Vector Shape: torch.Size([32, 768])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "import numpy as np\n",
        "\n",
        "# np.random.seed(42)\n",
        "# torch.manual_seed(42)\n",
        "\n",
        "# Parameters for synthetic data\n",
        "num_samples = 1000\n",
        "train_ratio = 0.7\n",
        "val_ratio = 0.2\n",
        "batch_size = 32\n",
        "time_series_dim = 100  # Dimensionality of time series data\n",
        "nlp_vector_dim = 768  # Dimensionality of NLP vector data\n",
        "z_dim = 64  # Latent variable dimension\n",
        "\n",
        "# Generate synthetic time series data (e.g., sensor data)\n",
        "time_series_data = np.random.rand(num_samples, time_series_dim).astype(np.float32)\n",
        "\n",
        "# Generate synthetic NLP vector data (e.g., embeddings from a language model)\n",
        "nlp_vector_data = np.random.rand(num_samples, nlp_vector_dim).astype(np.float32)\n",
        "\n",
        "# Convert data to tensors\n",
        "time_series_tensor = torch.tensor(time_series_data)\n",
        "nlp_vector_tensor = torch.tensor(nlp_vector_data)\n",
        "\n",
        "# Create TensorDataset and DataLoader\n",
        "dataset = TensorDataset(time_series_tensor, nlp_vector_tensor)\n",
        "\n",
        "# Split dataset into train, validation, and test sets\n",
        "train_size = int(train_ratio * num_samples)\n",
        "val_size = int(val_ratio * num_samples)\n",
        "test_size = num_samples - train_size - val_size\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# Create DataLoaders\n",
        "generator = torch.Generator()\n",
        "generator.manual_seed(42)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, generator=generator)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "# Display sample data\n",
        "sample_time_series, sample_nlp_vector = next(iter(train_loader))\n",
        "print(\"Sample Time Series Shape:\", sample_time_series.shape)\n",
        "print(\"Sample NLP Vector Shape:\", sample_nlp_vector.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pixyz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhqCdCGwL3Gl",
        "outputId": "0d88a72e-c908-48f9-fd94-1975931aa72f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pixyz\n",
            "  Downloading pixyz-0.3.3-py3-none-any.whl.metadata (14 kB)\n",
            "\u001b[33mWARNING: Ignoring version 0.3.3 of pixyz since it has invalid metadata:\n",
            "Requested pixyz from https://files.pythonhosted.org/packages/8f/c3/35083628485cd09c2be0216f8c434b40a877561d44dde2f2b1fe934412d3/pixyz-0.3.3-py3-none-any.whl has invalid metadata: Expected matching RIGHT_PARENTHESIS for LEFT_PARENTHESIS, after version specifier\n",
            "    flake8 (==3.9.2pytest-cov) ; extra == 'dev'\n",
            "           ~~~~~~~~^\n",
            "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
            "\u001b[0m  Downloading pixyz-0.3.2-py3-none-any.whl.metadata (13 kB)\n",
            "  Using cached pixyz-0.3.3-py3-none-any.whl.metadata (14 kB)\n",
            "\u001b[33mWARNING: Ignoring version 0.3.3 of pixyz since it has invalid metadata:\n",
            "Requested pixyz from https://files.pythonhosted.org/packages/8f/c3/35083628485cd09c2be0216f8c434b40a877561d44dde2f2b1fe934412d3/pixyz-0.3.3-py3-none-any.whl has invalid metadata: Expected matching RIGHT_PARENTHESIS for LEFT_PARENTHESIS, after version specifier\n",
            "    flake8 (==3.9.2pytest-cov) ; extra == 'dev'\n",
            "           ~~~~~~~~^\n",
            "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: torch>=1.0 in /usr/local/lib/python3.11/dist-packages (from pixyz) (2.5.1+cu121)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pixyz) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pixyz) (1.26.4)\n",
            "Requirement already satisfied: sympy>=1.4 in /usr/local/lib/python3.11/dist-packages (from pixyz) (1.13.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from pixyz) (7.34.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pixyz) (3.4.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.4->pixyz) (1.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->pixyz) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->pixyz) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->pixyz) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->pixyz) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->pixyz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->pixyz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->pixyz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->pixyz) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->pixyz) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->pixyz) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->pixyz) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->pixyz) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->pixyz) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->pixyz) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->pixyz) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->pixyz) (3.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0->pixyz) (12.6.85)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython->pixyz) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython->pixyz)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->pixyz) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->pixyz) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython->pixyz) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->pixyz) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->pixyz) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->pixyz) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->pixyz) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->pixyz) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->pixyz) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->pixyz) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->pixyz) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0->pixyz) (3.0.2)\n",
            "Downloading pixyz-0.3.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.3/71.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi, pixyz\n",
            "Successfully installed jedi-0.19.2 pixyz-0.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_dim_ts = 100  # 時系列データの次元数\n",
        "y_dim_nlp = 768  # 言語ベクトルの次元数 (例: BERT埋め込み)\n",
        "z_dim = 64  # 潜在変数の次元数"
      ],
      "metadata": {
        "id": "BpvhXi6pLNV7"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pixyz.distributions import Normal, Bernoulli, Categorical\n",
        "from pixyz.losses import KullbackLeibler\n",
        "from pixyz.models import VAE\n",
        "from pixyz.utils import print_latex\n",
        "# from __future__ import print_function\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms\n",
        "# from tensorboardX import SummaryWriter\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "class Inference(Normal):\n",
        "    def __init__(self):\n",
        "        super(Inference, self).__init__(var=[\"z\"], cond_var=[\"x_ts\", \"y_nlp\"], name=\"q\")\n",
        "\n",
        "        self.fc1 = nn.Linear(x_dim_ts + y_dim_nlp, 512)\n",
        "        self.fc2 = nn.Linear(512, 512)\n",
        "        self.fc31 = nn.Linear(512, z_dim)\n",
        "        self.fc32 = nn.Linear(512, z_dim)\n",
        "\n",
        "    def forward(self, x_ts, y_nlp):\n",
        "        h = F.relu(self.fc1(torch.cat([x_ts, y_nlp], 1)))\n",
        "        h = F.relu(self.fc2(h))\n",
        "        return {\"loc\": self.fc31(h), \"scale\": F.softplus(self.fc32(h))}\n",
        "\n",
        "class InferenceX(Normal):\n",
        "    def __init__(self):\n",
        "        super(InferenceX, self).__init__(var=[\"z\"], cond_var=[\"x_ts\"], name=\"q\")\n",
        "\n",
        "        self.fc1 = nn.Linear(x_dim_ts, 512)\n",
        "        self.fc2 = nn.Linear(512, 512)\n",
        "        self.fc31 = nn.Linear(512, z_dim)\n",
        "        self.fc32 = nn.Linear(512, z_dim)\n",
        "\n",
        "    def forward(self, x_ts):\n",
        "        h = F.relu(self.fc1(x_ts))\n",
        "        h = F.relu(self.fc2(h))\n",
        "        return {\"loc\": self.fc31(h), \"scale\": F.softplus(self.fc32(h))}\n",
        "\n",
        "class InferenceY(Normal):\n",
        "    def __init__(self):\n",
        "        super(InferenceY, self).__init__(var=[\"z\"], cond_var=[\"y_nlp\"], name=\"q\")\n",
        "\n",
        "        self.fc1 = nn.Linear(y_dim_nlp, 512)\n",
        "        self.fc2 = nn.Linear(512, 512)\n",
        "        self.fc31 = nn.Linear(512, z_dim)\n",
        "        self.fc32 = nn.Linear(512, z_dim)\n",
        "\n",
        "    def forward(self, y_nlp):\n",
        "        h = F.relu(self.fc1(y_nlp))\n",
        "        h = F.relu(self.fc2(h))\n",
        "        return {\"loc\": self.fc31(h), \"scale\": F.softplus(self.fc32(h))}\n",
        "\n",
        "class GeneratorX(Bernoulli):\n",
        "    def __init__(self):\n",
        "        super(GeneratorX, self).__init__(var=[\"x_ts\"], cond_var=[\"z\"], name=\"p\")\n",
        "\n",
        "        self.fc1 = nn.Linear(z_dim, 512)\n",
        "        self.fc2 = nn.Linear(512, 512)\n",
        "        self.fc3 = nn.Linear(512, x_dim_ts)\n",
        "\n",
        "    def forward(self, z):\n",
        "        h = F.relu(self.fc1(z))\n",
        "        h = F.relu(self.fc2(h))\n",
        "        return {\"probs\": torch.sigmoid(self.fc3(h))}\n",
        "\n",
        "class GeneratorY(Normal):\n",
        "    def __init__(self):\n",
        "        super(GeneratorY, self).__init__(var=[\"y_nlp\"], cond_var=[\"z\"], name=\"p\")\n",
        "\n",
        "        self.fc1 = nn.Linear(z_dim, 512)\n",
        "        self.fc2 = nn.Linear(512, 512)\n",
        "        self.fc3 = nn.Linear(512, y_dim_nlp)\n",
        "\n",
        "    def forward(self, z):\n",
        "        h = F.relu(self.fc1(z))\n",
        "        h = F.relu(self.fc2(h))\n",
        "        return {\"loc\": self.fc3(h), \"scale\": torch.ones_like(self.fc3(h))}  # 分散は固定値\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# prior model p(z)\n",
        "prior = Normal(loc=torch.tensor(0.), scale=torch.tensor(1.),\n",
        "               var=[\"z\"], features_shape=[z_dim], name=\"p_{prior}\").to(device)\n",
        "\n",
        "p_x = GeneratorX().to(device)\n",
        "p_y = GeneratorY().to(device)\n",
        "\n",
        "q = Inference().to(device)\n",
        "q_x = InferenceX().to(device)\n",
        "q_y = InferenceY().to(device)\n",
        "\n",
        "p = p_x * p_y\n",
        "\n",
        "kl = KullbackLeibler(q, prior)\n",
        "kl_x = KullbackLeibler(q, q_x)\n",
        "kl_y = KullbackLeibler(q, q_y)\n",
        "\n",
        "regularizer = kl + kl_x + kl_y\n",
        "\n",
        "print(p)\n",
        "print_latex(p)\n",
        "\n",
        "print(regularizer)\n",
        "print_latex(regularizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "j0Sl33E0LNYA",
        "outputId": "a285f4ca-9f46-4031-c0f6-bf77d32a70cf"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution:\n",
            "  p(x_{ts},y_{nlp}|z) = p(y_{nlp}|z)p(x_{ts}|z)\n",
            "Network architecture:\n",
            "  p(x_{ts}|z):\n",
            "  GeneratorX(\n",
            "    name=p, distribution_name=Bernoulli,\n",
            "    var=['x_ts'], cond_var=['z'], input_var=['z'], features_shape=torch.Size([])\n",
            "    (fc1): Linear(in_features=64, out_features=512, bias=True)\n",
            "    (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (fc3): Linear(in_features=512, out_features=100, bias=True)\n",
            "  )\n",
            "  p(y_{nlp}|z):\n",
            "  GeneratorY(\n",
            "    name=p, distribution_name=Normal,\n",
            "    var=['y_nlp'], cond_var=['z'], input_var=['z'], features_shape=torch.Size([])\n",
            "    (fc1): Linear(in_features=64, out_features=512, bias=True)\n",
            "    (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (fc3): Linear(in_features=512, out_features=768, bias=True)\n",
            "  )\n",
            "D_{KL} \\left[q(z|x_{ts},y_{nlp})||p_{prior}(z) \\right] + D_{KL} \\left[q(z|x_{ts},y_{nlp})||q(z|x_{ts}) \\right] + D_{KL} \\left[q(z|x_{ts},y_{nlp})||q(z|y_{nlp}) \\right]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Math object>"
            ],
            "text/latex": "$\\displaystyle D_{KL} \\left[q(z|x_{ts},y_{nlp})||p_{prior}(z) \\right] + D_{KL} \\left[q(z|x_{ts},y_{nlp})||q(z|x_{ts}) \\right] + D_{KL} \\left[q(z|x_{ts},y_{nlp})||q(z|y_{nlp}) \\right]$"
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = VAE(q, p, other_distributions=[q_x, q_y],\n",
        "            regularizer=regularizer, optimizer=optim.Adam, optimizer_params={\"lr\":1e-3})\n",
        "print(model)\n",
        "print_latex(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "mSqHjbweMoOE",
        "outputId": "6e02a4f4-007f-4f92-a873-92d19fc0231c"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distributions (for training):\n",
            "  q(z|x_{ts},y_{nlp}), p(x_{ts},y_{nlp}|z), q(z|x_{ts}), q(z|y_{nlp})\n",
            "Loss function:\n",
            "  mean \\left(D_{KL} \\left[q(z|x_{ts},y_{nlp})||p_{prior}(z) \\right] + D_{KL} \\left[q(z|x_{ts},y_{nlp})||q(z|x_{ts}) \\right] + D_{KL} \\left[q(z|x_{ts},y_{nlp})||q(z|y_{nlp}) \\right] - \\mathbb{E}_{q(z|x_{ts},y_{nlp})} \\left[\\log p(x_{ts},y_{nlp}|z) \\right] \\right)\n",
            "Optimizer:\n",
            "  Adam (\n",
            "  Parameter Group 0\n",
            "      amsgrad: False\n",
            "      betas: (0.9, 0.999)\n",
            "      capturable: False\n",
            "      differentiable: False\n",
            "      eps: 1e-08\n",
            "      foreach: None\n",
            "      fused: None\n",
            "      lr: 0.001\n",
            "      maximize: False\n",
            "      weight_decay: 0\n",
            "  )\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Math object>"
            ],
            "text/latex": "$\\displaystyle mean \\left(D_{KL} \\left[q(z|x_{ts},y_{nlp})||p_{prior}(z) \\right] + D_{KL} \\left[q(z|x_{ts},y_{nlp})||q(z|x_{ts}) \\right] + D_{KL} \\left[q(z|x_{ts},y_{nlp})||q(z|y_{nlp}) \\right] - \\mathbb{E}_{q(z|x_{ts},y_{nlp})} \\left[\\log p(x_{ts},y_{nlp}|z) \\right] \\right)$"
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "def train_model(model, train_loader, val_loader, num_epochs=20):\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_model_state = None\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # model.train()\n",
        "        train_loss = 0\n",
        "\n",
        "        for x_ts, y_nlp in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "            x_ts, y_nlp = x_ts.to(device), y_nlp.to(device)\n",
        "            loss = model.train({\"x_ts\": x_ts, \"y_nlp\": y_nlp})\n",
        "            train_loss += loss\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        # model.eval()\n",
        "        val_loss = 0\n",
        "\n",
        "        latent_vars = []\n",
        "        with torch.no_grad():\n",
        "            for x_ts, y_nlp in val_loader:\n",
        "                x_ts, y_nlp = x_ts.to(device), y_nlp.to(device)\n",
        "                loss = model.test({\"x_ts\": x_ts, \"y_nlp\": y_nlp})\n",
        "                val_loss += loss\n",
        "\n",
        "                posterior_params = q(x_ts=x_ts, y_nlp=y_nlp)\n",
        "                loc = posterior_params[\"loc\"]\n",
        "                scale = posterior_params[\"scale\"]\n",
        "                set_seed(42) # 再現性の担保のため、ここに記載必要あり\n",
        "                z = loc + scale * torch.randn_like(scale)\n",
        "                latent_vars.append(z.cpu().numpy())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_state = model.save('jmvae')\n",
        "\n",
        "    print(\"Training complete. Best validation loss: {:.4f}\".format(best_val_loss))\n",
        "    return np.concatenate(latent_vars, axis=0)\n",
        "    # return best_model_state\n",
        "\n",
        "# Extract latent variables\n",
        "def extract_latent_variables(model, data_loader):\n",
        "    # model.eval()\n",
        "    latent_vars = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_ts, y_nlp in data_loader:\n",
        "            x_ts, y_nlp = x_ts.to(device), y_nlp.to(device)\n",
        "            posterior_params = q(x_ts=x_ts, y_nlp=y_nlp)\n",
        "            loc = posterior_params[\"loc\"]\n",
        "            scale = posterior_params[\"scale\"]\n",
        "            set_seed(42) # 再現性の担保のため、ここに記載必要あり\n",
        "            z = loc + scale * torch.randn_like(scale)\n",
        "            latent_vars.append(z.cpu().numpy())\n",
        "\n",
        "    return np.concatenate(latent_vars, axis=0)\n",
        "\n",
        "# Train the model\n",
        "train_model(model, train_loader, test_loader, num_epochs=1)\n",
        "model.load('jmvae')\n",
        "\n",
        "# Extract latent variables from the test dataset\n",
        "z_test = extract_latent_variables(model, test_loader)\n",
        "print(\"Extracted latent variables shape:\", z_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRZCqg3xLNaP",
        "outputId": "9ba27074-aa35-40ff-d9d2-a20a91f90720"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1: 100%|██████████| 22/22 [00:00<00:00, 26.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, Train Loss: 808.8531, Val Loss: 808.1407\n",
            "Training complete. Best validation loss: 808.1407\n",
            "Extracted latent variables shape: (100, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR4JkEwyWEa9",
        "outputId": "a90f3aa5-bc36-4c79-da66-1b58f8ecd93a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.36885163, -1.0428203 ,  1.0490055 , ...,  1.3436681 ,\n",
              "         0.15581864,  1.6411437 ],\n",
              "       [-0.7159389 ,  0.48006743,  0.48653144, ..., -0.5092131 ,\n",
              "         0.69968843, -0.23747133],\n",
              "       [-0.93877834,  1.3061308 ,  0.86554307, ..., -0.20429112,\n",
              "        -1.0778545 ,  0.01420994],\n",
              "       ...,\n",
              "       [ 1.5985991 ,  0.47357184,  1.981343  , ...,  1.5515734 ,\n",
              "        -1.649648  , -1.3414232 ],\n",
              "       [-1.5919024 ,  1.5516188 ,  1.5557631 , ...,  0.7525108 ,\n",
              "        -0.04126738,  0.8054824 ],\n",
              "       [-0.9444447 ,  0.47623128,  0.5947096 , ..., -0.28634986,\n",
              "         0.2976985 , -0.42944926]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQVF133EYJbm",
        "outputId": "6d4c9ea3-8fbb-41e5-f174-783bfb0981d7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.80054146,  0.34293288, -1.9371177 , ..., -0.67033124,\n",
              "         1.7463284 ,  0.9668151 ],\n",
              "       [-0.9628307 ,  1.9619235 ,  0.72652674, ...,  1.0903841 ,\n",
              "        -0.20802382,  0.53745055],\n",
              "       [-0.5212683 ,  2.9598465 , -0.3258235 , ...,  0.22248146,\n",
              "         1.1281545 , -1.2441776 ],\n",
              "       ...,\n",
              "       [ 1.0885067 ,  0.52142954, -0.8099768 , ...,  0.10907855,\n",
              "         1.5081668 ,  0.5507123 ],\n",
              "       [ 1.3673116 , -0.15788765,  1.1597885 , ..., -0.16008048,\n",
              "        -0.16548574,  0.07460947],\n",
              "       [ 0.5198291 ,  0.47770068, -1.1652261 , ...,  1.8560479 ,\n",
              "         1.453478  , -0.00462941]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def set_seed(seed: int):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# シードを固定\n",
        "set_seed(42)\n",
        "\n",
        "# loc と scale の設定\n",
        "loc = torch.tensor([0.5, 1.0, 1.5])\n",
        "scale = torch.tensor([0.1, 0.2, 0.3])\n",
        "\n",
        "# サンプリング\n",
        "set_seed(42)\n",
        "z = loc + scale * torch.randn_like(scale)\n",
        "print(\"Sampled z:\", z)\n",
        "\n",
        "# 再実行しても同じ結果になる\n",
        "set_seed(42)\n",
        "z_repeated = loc + scale * torch.randn_like(scale)\n",
        "print(\"Sampled z (repeated):\", z_repeated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeXh-nGXYOrE",
        "outputId": "82cdb4b8-a147-4da5-a884-afaaf8f5f6ff"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampled z: tensor([0.5337, 1.0258, 1.5703])\n",
            "Sampled z (repeated): tensor([0.5337, 1.0258, 1.5703])\n"
          ]
        }
      ]
    }
  ]
}